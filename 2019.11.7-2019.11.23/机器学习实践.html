<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>机器学习实践</title>
</head>
<body>
<div id="wmd-preview" class="wmd-preview"><div class="md-section-divider"></div><div class="md-section-divider"></div><h1 data-anchor-id="i6ap" id="机器学习实践">机器学习实践</h1><p data-anchor-id="xmdi"><code>实验</code></p><hr><div class="md-section-divider"></div><h3 data-anchor-id="igrp" id="一anaconda相关使用方法">一、anaconda相关使用方法</h3><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="nb9o"><ol class="linenums"><li class="L0"><code><span class="pln">$ conda </span><span class="pun">--</span><span class="pln">version  </span><span class="com">//查看anaconda的版本</span></code></li><li class="L1"><code><span class="pln">$ conda update conda  </span><span class="com">//anaconda更新</span></code></li><li class="L2"><code><span class="pln">$ conda create </span><span class="pun">--</span><span class="pln">name new_environment packet  </span><span class="com">//新建一个环境，并在其中安装相关的数据包</span></code></li><li class="L3"><code><span class="pln">$ conda info </span><span class="pun">--</span><span class="pln">envs  </span><span class="com">//查看conda环境信息</span></code></li><li class="L4"><code><span class="pln">$ conda list  </span><span class="com">//查看conda环境中安装的软件包</span></code></li><li class="L5"><code><span class="pln">$ conda install packet  </span><span class="com">//在conda环境中安装对应的软件包</span></code></li></ol></pre><div class="md-section-divider"></div><h3 data-anchor-id="yetg" id="二jupyter-notebook的使用方法">二、jupyter notebook的使用方法</h3><p data-anchor-id="qno2"><a href="https://jupyter-notebook.readthedocs.io/en/latest/notebook.html" target="_blank">jupyter notebook的使用方法</a></p><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="ia4a"><ol class="linenums"><li class="L0"><code><span class="pln">$ jupyter notebook notebook</span><span class="pun">.</span><span class="pln">ipynb  </span><span class="com">//打开jupyter notebook文件</span></code></li><li class="L1"><code><span class="pln">$ jupyter notebook </span><span class="pun">--</span><span class="pln">port </span><span class="lit">9999</span><span class="pln">  </span><span class="com">//自定义连接的服务器端口。默认端口为8888</span></code></li><li class="L2"><code><span class="pln">$ jupyter notebook </span><span class="pun">--</span><span class="kwd">no</span><span class="pun">-</span><span class="pln">browser  </span><span class="com">//不打开浏览器</span></code></li><li class="L3"><code><span class="pln">$ jupyter notebook </span><span class="pun">--</span><span class="pln">help  </span><span class="com">//获取帮助信息</span></code></li></ol></pre><p data-anchor-id="ngss">可以直接从第三部分 <strong>Notebook 用户接口</strong>（Notebook user interface）部分读起。</p><p data-anchor-id="niy8">1、基本接口 <br>
<img src="https://s2.ax1x.com/2019/11/04/KvuxPO.png" alt="KvuxPO.png" title=""></p><ul data-anchor-id="gf69">
<li>notebook name：在Untitled位置修改文件名称。文件格式为.ipynb。</li>
<li>menu bar：基本功能都在这个位置。</li>
<li>tool bar：快捷键，简化版的menu bar。</li>
<li>code cell：写代码的位置。</li>
</ul><p data-anchor-id="h339">2、notebook结构 <br>
notebook由多个code cell组成。每一个code cell都是可以进行多行文本输入，内容可以由 <strong>shift-enter</strong> 执行，或是toolbar-Run(运行)，或者menubar-cell-run（单元格-运行..）。执行的动作由文件类型决定。类型分为：</p><ul data-anchor-id="9gc2">
<li>code cell：可以写代码，并运行代码，但是编程语言取决于内核，一般默认为python。运行之后，代码被交由内核执行，再将结果返回给当前窗口。而且显示结果不限于文本，可以是matlibplot的图像，也可以是HTML的表格。 <strong>但是具体怎么显示这些，还有待学习。</strong></li>
<li>markdown cell： 在cell-cell type中修改，语法还是markdown的语法。</li>
<li>raw cell： <strong>暂时不用</strong></li>
</ul><div class="md-section-divider"></div><h3 data-anchor-id="wqb9" id="三编写机器学习算法利用之前搭建的环境">三、编写机器学习算法（利用之前搭建的环境）</h3><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="hnfb"><ol class="linenums"><li class="L0"><code><span class="pln">$ conda activate  </span><span class="com">//打开conda环境</span></code></li><li class="L1"><code><span class="pln">$ </span><span class="pun">(</span><span class="kwd">base</span><span class="pun">)</span><span class="pln"> jupyter notebook  </span><span class="com">//在浏览器中进入编辑器</span></code></li></ol></pre><p data-anchor-id="9kqr">1、环境简介</p><ul data-anchor-id="ftn6">
<li><a href="https://www.numpy.org.cn/user/" target="_blank">NumPy</a>：提供快速的多维数组操作。</li>
<li><a href="https://www.pypandas.cn/docs/getting_started/overview.html" target="_blank">pandas</a>：核心数据分析支持库，提供了快速、灵活、明确的数据结构，旨在简单、直观地处理关系型、标记型数据。</li>
<li>SciPy：对Numpy中的多维数组进行计算。</li>
<li>matplotlib：提供图像处理的技术，主要用于处理结果的可视化。</li>
<li><a href="https://github.com/apachecn/sklearn-doc-zh" target="_blank">scikit-learn</a>：建立在NumPy、SciPy和matplotlib，其中包含多种机器学习算法，主要提供分类、回归、聚类、数据降维、模型选择和数据预处理。</li>
</ul><p data-anchor-id="463p">2、基本步骤 <br>
（1）导入相关的软件包</p><p data-anchor-id="je8p">（2）导入数据并处理</p><ul data-anchor-id="javg">
<li>从scikit-learn中导入鸢尾花数据（也可以从外部导入数据）</li>
</ul><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="hqyr"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn </span><span class="kwd">import</span><span class="pln"> datasets</span></code></li><li class="L1"><code class="language-python"><span class="kwd">import</span><span class="pln"> numpy </span><span class="kwd">as</span><span class="pln"> np</span></code></li><li class="L2"><code class="language-python"><span class="com"># 导入鸢尾花数据</span></code></li><li class="L3"><code class="language-python"><span class="pln">iris </span><span class="pun">=</span><span class="pln"> datasets</span><span class="pun">.</span><span class="pln">load_iris</span><span class="pun">()</span><span class="pln">  </span></code></li><li class="L4"><code class="language-python"><span class="com"># 取所有数据的第三、四列（选取的两个特征）给X</span></code></li><li class="L5"><code class="language-python"><span class="pln">X </span><span class="pun">=</span><span class="pln"> iris</span><span class="pun">.</span><span class="pln">data</span><span class="pun">[:,</span><span class="pln"> </span><span class="pun">[</span><span class="lit">2</span><span class="pun">,</span><span class="pln"> </span><span class="lit">3</span><span class="pun">]]</span><span class="pln">  </span></code></li><li class="L6"><code class="language-python"><span class="com">#将样本的分类结果交给y</span></code></li><li class="L7"><code class="language-python"><span class="pln">y </span><span class="pun">=</span><span class="pln"> iris</span><span class="pun">.</span><span class="pln">target  </span></code></li></ol></pre><ul data-anchor-id="wr7l">
<li>设置训练数据和测试数据</li>
</ul><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="1ygn"><ol class="linenums"><li class="L0"><code class="language-python"><span class="com"># 通过版本号选取不同的导入命令</span></code></li><li class="L1"><code class="language-python"><span class="kwd">if</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">__version__ </span><span class="pun">&lt;</span><span class="pln"> </span><span class="str">'0.18'</span><span class="pun">:</span><span class="pln"> </span></code></li><li class="L2"><code class="language-python"><span class="pln">    </span><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">cross_validation </span><span class="kwd">import</span><span class="pln"> train_test_split</span></code></li><li class="L3"><code class="language-python"><span class="kwd">else</span><span class="pun">:</span></code></li><li class="L4"><code class="language-python"><span class="pln">    </span><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">model_selection </span><span class="kwd">import</span><span class="pln"> train_test_split</span></code></li><li class="L5"><code class="language-python"><span class="com"># 将导入的数据分为训练数据和测试数据，test_size表明测试数据所占的比重</span></code></li><li class="L6"><code class="language-python"><span class="pln">X_train</span><span class="pun">,</span><span class="pln"> X_test</span><span class="pun">,</span><span class="pln"> y_train</span><span class="pun">,</span><span class="pln"> y_test </span><span class="pun">=</span><span class="pln"> train_test_split</span><span class="pun">(</span><span class="pln">X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">,</span><span class="pln"> test_size</span><span class="pun">=</span><span class="lit">0.3</span><span class="pun">,</span><span class="pln"> random_state</span><span class="pun">=</span><span class="lit">0</span><span class="pun">)</span></code></li></ol></pre><ul data-anchor-id="jk0q">
<li>对训练数据和测试数据进行标准化</li>
</ul><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="jaqe"><ol class="linenums"><li class="L0"><code class="language-python"><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">preprocessing </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">StandardScaler</span></code></li><li class="L1"><code class="language-python"><span class="pln">sc </span><span class="pun">=</span><span class="pln"> </span><span class="typ">StandardScaler</span><span class="pun">()</span></code></li><li class="L2"><code class="language-python"><span class="com"># 计算训练数据中的平均值和标准差（先拟合数据，形成模型）</span></code></li><li class="L3"><code class="language-python"><span class="pln">sc</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X_train</span><span class="pun">)</span></code></li><li class="L4"><code class="language-python"><span class="com"># 对数据进行标准化</span></code></li><li class="L5"><code class="language-python"><span class="pln">X_train_std </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">transform</span><span class="pun">(</span><span class="pln">X_train</span><span class="pun">)</span></code></li><li class="L6"><code class="language-python"><span class="pln">X_test_std </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">transform</span><span class="pun">(</span><span class="pln">X_test</span><span class="pun">)</span></code></li></ol></pre><p data-anchor-id="d6fr">（3）算法执行（<a href="https://scikit-learn.org/dev/modules/classes.html" target="_blank">算法参数</a>）</p><ul data-anchor-id="so0e">
<li><strong>感知器</strong></li>
</ul><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="tdob"><ol class="linenums"><li class="L0"><code><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">linear_model </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">Perceptron</span></code></li><li class="L1"><code><span class="com"># 生成感知器对象</span></code></li><li class="L2"><code><span class="pln">ppn </span><span class="pun">=</span><span class="pln"> </span><span class="typ">Perceptron</span><span class="pun">()</span></code></li><li class="L3"><code><span class="com"># 训练数据</span></code></li><li class="L4"><code><span class="pln">ppn</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X_train_std</span><span class="pun">,</span><span class="pln"> y_train</span><span class="pun">)</span></code></li><li class="L5"><code><span class="com"># 输出为：Perceptron(alpha=0.0001, class_weight=None, eta0=0.1, fit_intercept=True,n_iter=40, n_jobs=1, penalty=None, random_state=0, shuffle=True,verbose=0, warm_start=False)</span></code></li></ol></pre><p data-anchor-id="zi8o">参数说明</p><ul data-anchor-id="gxi1">
<li class="todo-list-item"><i class="icon-check-empty"></i>alpha：正则化系数，默认0.0001。</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>class_weight:</li>
<li class="todo-list-item"><i class="icon-check-sign"></i>eta0：学习速率;</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>fit_intercept：</li>
<li class="todo-list-item"><i class="icon-check-sign"></i>n_iter：迭代次数；</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>n_jobs：算法运行使用计算机的内核数量；</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>penalty：要使用的惩罚项，正则化中的术语，默认为无；</li>
<li class="todo-list-item"><i class="icon-check-sign"></i>random_state：每次迭代后重拍训练数据集，int值；</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>shuffle：是否洗牌；</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>verbose：</li>
<li class="todo-list-item"><p><i class="icon-check-empty"></i>warm_state：</p></li>
<li><p><strong>逻辑斯特分类（交叉熵）</strong></p></li>
</ul><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="dn2g"><ol class="linenums"><li class="L0"><code><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">linear_model </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">LogisticRegression</span></code></li><li class="L1"><code><span class="pln">lr </span><span class="pun">=</span><span class="pln"> </span><span class="typ">LogisticRegression</span><span class="pun">(</span><span class="pln">C</span><span class="pun">=</span><span class="lit">1000.0</span><span class="pun">,</span><span class="pln"> random_state</span><span class="pun">=</span><span class="lit">0</span><span class="pun">)</span></code></li><li class="L2"><code><span class="pln">lr</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X_train_std</span><span class="pun">,</span><span class="pln"> y_train</span><span class="pun">)</span></code></li></ol></pre><p data-anchor-id="91w8">参数说明</p><ul data-anchor-id="cfoc">
<li class="todo-list-item"><i class="icon-check-empty"></i>C：正则化系数的倒数，减小C，相当于增加正则化的强度，会使权重系数逐渐收缩；</li>
<li class="todo-list-item"><p><i class="icon-check-sign"></i>random_state：每次迭代后重拍训练数据集，int值。</p></li>
<li><p>SVM </p></li>
</ul><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="hens"><ol class="linenums"><li class="L0"><code><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">svm </span><span class="kwd">import</span><span class="pln"> SVC</span></code></li><li class="L1"><code><span class="pln">svm </span><span class="pun">=</span><span class="pln"> SVC</span><span class="pun">(</span><span class="pln">kernel</span><span class="pun">=</span><span class="str">'linear'</span><span class="pun">,</span><span class="pln"> C</span><span class="pun">=</span><span class="lit">1.0</span><span class="pun">,</span><span class="pln"> random_state</span><span class="pun">=</span><span class="lit">0</span><span class="pun">)</span></code></li><li class="L2"><code><span class="pln">svm</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X_train_std</span><span class="pun">,</span><span class="pln"> y_train</span><span class="pun">)</span></code></li></ol></pre><p data-anchor-id="vtif"><a href="https://blog.csdn.net/guanyuqiu/article/details/85109441" target="_blank">参数说明</a></p><ul data-anchor-id="v0eh">
<li class="todo-list-item"><i class="icon-check-sign"></i>C：惩罚参数</li>
</ul><blockquote data-anchor-id="co98" class="white-blockquote">
  <p>默认值为1。惩罚参数是由于松弛变量而加入的，它表征的是对错误分类的惩罚程度，也就是不允许分类出错的程度。C越大，表明越不允许分类出错，越可能过拟合。C太小，趋于0的话，分类将不会关注分类是否正确的问题，只要求间隔 越大越好，此时分类也没有意义。</p>
</blockquote><ul data-anchor-id="p9d8">
<li class="todo-list-item"><i class="icon-check-sign"></i>Kernel：核函数</li>
</ul><blockquote data-anchor-id="k01x" class="white-blockquote">
  <p>核函数的引入是为了解决线性不可分的问题，将分类点映射的高维空间中以后，转化为可线性分割的问题。</p>
  
  <p>kernel = 'linear'时，为线性核，C越大分类效果越好，但可能会过拟合； <br>
  kernel = 'rbf'时，为高斯核（默认值）。gamma值越小，支撑向量越多，分类界面越连续；gamma值越大，分类界面越“散”，分类效果越好，但可能会过拟合； <br>
  kernel = 'poly'时，为多项式核； <br>
  kernel = 'sigmoid'时，为Sigmoid核函数；  <br>
  kernel = 'precomputed'时，为核矩阵。</p>
</blockquote><ul data-anchor-id="7kl3">
<li class="todo-list-item"><i class="icon-check-empty"></i>decision_function_shape参数</li>
</ul><blockquote data-anchor-id="zlmf" class="white-blockquote">
  <p>decision_function_shape='ovr'时，为one v rest，即一个类别与其他ov类别进行划分； <br>
  decision_function_shape='ovo'时，为one v one，即将类别两两进行划分，用二分类的方法模拟多分类的结果。</p>
</blockquote><ul data-anchor-id="1f0o">
<li class="todo-list-item"><i class="icon-check-empty"></i>degree：多项式poly函数的维度，默认是3，选择其他核函数时会被忽略;</li>
<li class="todo-list-item"><i class="icon-check-sign"></i>gamma：kernel = 'rbf'、'poly' 和'sigmoid'的核函数参数。默认是’auto’，则会选择1/n_features；</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>coef0：核函数的常数项。对于kernel = 'poly'和'sigmoid'有用；</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>probability：是否采用概率估计，默认为False；</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>shrinking：是否采用shirinking heuristic方法，默认为true；</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>cache_size：核函数cache缓存大小，默认为200（M）；</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>class_weight：每个类所占的权重，字典形式传递，不同的类设置不同的惩罚参数C（weight*C(C-SVC中的C)）, 默认为缺省（自适应）；</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>verbose：允许详细输出，多线程不建议开启，默认为False；</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>max_iter：最大迭代次数，-1为无限制；</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>random_state：每次迭代后重排训练数据集，int值。</li>
<li class="todo-list-item"><p><i class="icon-check-empty"></i>tol：停止训练的容许度，默认为0.001。</p></li>
<li><p>决策树</p></li>
</ul><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="qt35"><ol class="linenums"><li class="L0"><code><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">tree </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">DecisionTreeClassifier</span></code></li><li class="L1"><code><span class="pln">tree </span><span class="pun">=</span><span class="pln"> </span><span class="typ">DecisionTreeClassifier</span><span class="pun">(</span><span class="pln">criterion</span><span class="pun">=</span><span class="str">'entropy'</span><span class="pun">,</span><span class="pln"> max_depth</span><span class="pun">=</span><span class="lit">3</span><span class="pun">,</span><span class="pln"> random_state</span><span class="pun">=</span><span class="lit">0</span><span class="pun">)</span></code></li><li class="L2"><code><span class="pln">tree</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X_train</span><span class="pun">,</span><span class="pln"> y_train</span><span class="pun">)</span></code></li><li class="L3"><code><span class="com"># DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0</span></code></li></ol></pre><p data-anchor-id="4nbc"><a href="https://blog.csdn.net/li980828298/article/details/51172744" target="_blank">参数说明</a></p><ul data-anchor-id="s49l">
<li class="todo-list-item"><i class="icon-check-sign"></i>criterion：在选择区分特征时的评价标准，默认使用基尼系数。</li>
</ul><blockquote data-anchor-id="5jvu" class="white-blockquote">
  <p>'entropy'表明使用信息增益（计算熵变化的方法），'gini'表明使用基尼系数。</p>
</blockquote><ul data-anchor-id="hg6m">
<li class="todo-list-item"><i class="icon-check-empty"></i>splitter： 一种用来在节点中选择分类的策略，默认为'best'。</li>
</ul><blockquote data-anchor-id="7isp" class="white-blockquote">
  <p>支持的策略有'best'，选择最好的分类，'random'选择最好的随机分类。</p>
</blockquote><ul data-anchor-id="yg01">
<li class="todo-list-item"><i class="icon-check-empty"></i>max_features： 在进行分类时需要考虑的特征数，可以为int、float、string或者None类型，默认为None。</li>
</ul><blockquote data-anchor-id="zku6" class="white-blockquote">
  <p>如果是'int'，在每次分类是都要考虑max_features个特征； <br>
  如果是'float'，那么max_features是一个百分率并且分类时需要考虑的特征数是int(max_features*n_features,其中n_features是训练完成时发特征数)； <br>
  如果是'auto'，max_features=sqrt(n_features)； <br>
  如果是sqrt,max_features=sqrt(n_features)； <br>
  如果是log2,max_features=log2(n_features)； <br>
  如果是None，max_features=n_features。 <br>
  至少找到一个样本点有效的被分类时，搜索分类才会停止。</p>
</blockquote><ul data-anchor-id="f8fh">
<li class="todo-list-item"><i class="icon-check-sign"></i>max_depth：表示树的最大深度，int或者None类型（默认为None）。</li>
</ul><blockquote data-anchor-id="yx4h" class="white-blockquote">
  <p>如果是'None',则节点会一直扩展到所有的叶子都是纯的或者所有的叶子节点都包含少于min_samples_split个样本点。忽视max_leaf_nodes是不是为None。</p>
</blockquote><ul data-anchor-id="wclk">
<li class="todo-list-item"><i class="icon-check-empty"></i>min_samples_leaf：一个叶节点所需要的最小样本数，可以为int、float类型，默认为1。</li>
</ul><blockquote data-anchor-id="w22r" class="white-blockquote">
  <p>如果是'int'类型，则其为最小样本数。 <br>
  如果是'float'类型，则它是一个百分率并且ceil(min_samples_leaf*n_samples)是每个节点所需的样本数。</p>
</blockquote><ul data-anchor-id="ssus">
<li class="todo-list-item"><p><i class="icon-check-empty"></i>min_weight_fraction_leaf：一个叶节点的输入样本所需要的最小加权分数，float类型，默认为0。</p></li>
<li class="todo-list-item"><p><i class="icon-check-empty"></i>max_leaf_nodes：在最优方法中使用max_leaf_nodes构建一个树。可以为int、None，但是默认为None。如果是None则对叶节点的数目没有限制。如果不是None则不考虑max_depth。</p></li>
<li class="todo-list-item"><p><i class="icon-check-empty"></i>class_weight：表示在表{class_label:weight}中的类的关联权值。</p></li>
</ul><blockquote data-anchor-id="664u" class="white-blockquote">
  <p>可以为'dict'、'list of dicts'或者'Banlanced'或者None，默认为None。 <br>
  如果没有指定，则所有类的权值都为1。对于多输出问题，一列字典的顺序可以与一列y的次序相同。 <br>
  'balanced'模型使用y的值去自动适应权值，并且是以输入数据中类的频率的反比例。如：n_samples/(n_classes*np.bincount(y))。 <br>
  对于多输出，每列y的权值都会相乘。 <br>
  如果sample_weight已经指定了，这些权值将于samples以合适的方法相乘。</p>
</blockquote><ul data-anchor-id="c18v">
<li class="todo-list-item"><i class="icon-check-sign"></i>random_state：每次迭代后重排训练数据集，默认int值。</li>
</ul><blockquote data-anchor-id="qstu" class="white-blockquote">
  <p>如果是int，则为随机数字发生器的种子； <br>
  如果是RandomState，random_state是随机数字发生器； <br>
  如果是None，随机数字发生器是np.random使用的RandomState instance。</p>
</blockquote><ul data-anchor-id="0p1z">
<li class="todo-list-item"><i class="icon-check-empty"></i>persort：是否预分类数据以加速训练时最好分类的查找。bool类型，默认为False。</li>
</ul><blockquote data-anchor-id="nu2k" class="white-blockquote">
  <p>在有大数据集的决策树中，如果设为true可能会减慢训练的过程。当使用一个小数据集或者一个深度受限的决策树中，可以减速训练的过程。</p>
</blockquote><ul data-anchor-id="hnyl">
<li>随机森林</li>
</ul><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="ktwk"><ol class="linenums"><li class="L0"><code><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">ensemble </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">RandomForestClassifier</span></code></li><li class="L1"><code><span class="pln">forest </span><span class="pun">=</span><span class="pln"> </span><span class="typ">RandomForestClassifier</span><span class="pun">(</span><span class="pln">criterion</span><span class="pun">=</span><span class="str">'entropy'</span><span class="pun">,</span><span class="pln"> n_estimators</span><span class="pun">=</span><span class="lit">10</span><span class="pun">,</span><span class="pln"> random_state</span><span class="pun">=</span><span class="lit">1</span><span class="pun">,</span><span class="pln"> n_jobs</span><span class="pun">=</span><span class="lit">2</span><span class="pun">)</span></code></li><li class="L2"><code><span class="pln">forest</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X_train</span><span class="pun">,</span><span class="pln"> y_train</span><span class="pun">)</span></code></li></ol></pre><p data-anchor-id="pgc3">参数说明，<a href="https://blog.csdn.net/qq_16633405/article/details/61200502" target="_blank">额外参考</a></p><ul data-anchor-id="2ped">
<li class="todo-list-item"><i class="icon-check-sign"></i>criterion：在选择区分特征时的评价标准，默认使用基尼系数。</li>
</ul><blockquote data-anchor-id="203k" class="white-blockquote">
  <p>'entropy'表明使用信息增益（计算熵变化的方法），'gini'表明使用基尼系数。</p>
</blockquote><ul data-anchor-id="nb7g">
<li class="todo-list-item"><i class="icon-check-sign"></i>n_estimators：表明参与随机森林的“树”的棵树，即评估器的个数。</li>
<li class="todo-list-item"><i class="icon-check-sign"></i>random_state：每次迭代后重排训练数据集，默认int值。</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>n_jobs：使用的机器内核数量。</li>
<li class="todo-list-item"><i class="icon-check-empty"></i>max_features：随机森林允许单个决策树使用特征的最大数量。 </li>
</ul><blockquote data-anchor-id="eats" class="white-blockquote">
  <p>Auto/None ：简单地选取所有特征，每颗树都可以利用他们。这种情况下，每颗树都没有任何的限制； <br>
  sqrt ：此选项是每颗子树可以利用总特征数的平方根个，例如变量（特征）的总数是100，所以每颗子树只能取其中的10个； <br>
  log2：类似sqrt； <br>
  0.2：此选项允许每个随机森林的子树可以利用变特征数的20％。如果想考察的特征x％的作用，我们可以使用“0.X”的格式。</p>
</blockquote><ul data-anchor-id="mm4o">
<li>KNN</li>
</ul><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="lyyq"><ol class="linenums"><li class="L0"><code><span class="kwd">from</span><span class="pln"> sklearn</span><span class="pun">.</span><span class="pln">neighbors </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">KNeighborsClassifier</span></code></li><li class="L1"><code><span class="pln">knn </span><span class="pun">=</span><span class="pln"> </span><span class="typ">KNeighborsClassifier</span><span class="pun">(</span><span class="pln">n_neighbors</span><span class="pun">=</span><span class="lit">5</span><span class="pun">,</span><span class="pln"> p</span><span class="pun">=</span><span class="lit">2</span><span class="pun">,</span><span class="pln"> metric</span><span class="pun">=</span><span class="str">'minkowski'</span><span class="pun">)</span></code></li><li class="L2"><code><span class="pln">knn</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="pln">X_train_std</span><span class="pun">,</span><span class="pln"> y_train</span><span class="pun">)</span></code></li></ol></pre><p data-anchor-id="vyt1"><a href="https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier" target="_blank">参数说明</a></p><ul data-anchor-id="p3ti">
<li class="todo-list-item"><i class="icon-check-sign"></i>n_neighbors：邻居的数量，默认为5；</li>
<li class="todo-list-item"><i class="icon-check-sign"></i>p：表明使用哪种距离计算公式。</li>
</ul><blockquote data-anchor-id="g460" class="white-blockquote">
  <p>p=1，表明使用 <br>
  p=2，表示使用欧几里得距离；</p>
</blockquote><ul data-anchor-id="zf49">
<li class="todo-list-item"><i class="icon-check-sign"></i>metric：与参数p联合使用，值为'minkowski'。</li>
</ul><p data-anchor-id="hnhr">（4）画图显示</p><ul data-anchor-id="pfgf">
<li>显示函数</li>
</ul><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="cb12"><ol class="linenums"><li class="L0"><code><span class="kwd">from</span><span class="pln"> matplotlib</span><span class="pun">.</span><span class="pln">colors </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">ListedColormap</span></code></li><li class="L1"><code><span class="kwd">import</span><span class="pln"> matplotlib</span><span class="pun">.</span><span class="pln">pyplot </span><span class="kwd">as</span><span class="pln"> plt</span></code></li><li class="L2"><code><span class="kwd">import</span><span class="pln"> warnings</span></code></li><li class="L3"><code></code></li><li class="L4"><code><span class="kwd">def</span><span class="pln"> versiontuple</span><span class="pun">(</span><span class="pln">v</span><span class="pun">):</span></code></li><li class="L5"><code><span class="pln">    </span><span class="kwd">return</span><span class="pln"> tuple</span><span class="pun">(</span><span class="pln">map</span><span class="pun">(</span><span class="kwd">int</span><span class="pun">,</span><span class="pln"> </span><span class="pun">(</span><span class="pln">v</span><span class="pun">.</span><span class="pln">split</span><span class="pun">(</span><span class="str">"."</span><span class="pun">))))</span></code></li><li class="L6"><code></code></li><li class="L7"><code><span class="kwd">def</span><span class="pln"> plot_decision_regions</span><span class="pun">(</span><span class="pln">X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">,</span><span class="pln"> classifier</span><span class="pun">,</span><span class="pln"> test_idx</span><span class="pun">=</span><span class="kwd">None</span><span class="pun">,</span><span class="pln"> resolution</span><span class="pun">=</span><span class="lit">0.02</span><span class="pun">):</span></code></li><li class="L8"><code></code></li><li class="L9"><code><span class="pln">    </span><span class="com"># setup marker generator and color map</span></code></li><li class="L0"><code><span class="pln">    markers </span><span class="pun">=</span><span class="pln"> </span><span class="pun">(</span><span class="str">'s'</span><span class="pun">,</span><span class="pln"> </span><span class="str">'x'</span><span class="pun">,</span><span class="pln"> </span><span class="str">'o'</span><span class="pun">,</span><span class="pln"> </span><span class="str">'^'</span><span class="pun">,</span><span class="pln"> </span><span class="str">'v'</span><span class="pun">)</span></code></li><li class="L1"><code><span class="pln">    colors </span><span class="pun">=</span><span class="pln"> </span><span class="pun">(</span><span class="str">'red'</span><span class="pun">,</span><span class="pln"> </span><span class="str">'blue'</span><span class="pun">,</span><span class="pln"> </span><span class="str">'lightgreen'</span><span class="pun">,</span><span class="pln"> </span><span class="str">'gray'</span><span class="pun">,</span><span class="pln"> </span><span class="str">'cyan'</span><span class="pun">)</span></code></li><li class="L2"><code><span class="pln">    cmap </span><span class="pun">=</span><span class="pln"> </span><span class="typ">ListedColormap</span><span class="pun">(</span><span class="pln">colors</span><span class="pun">[:</span><span class="pln">len</span><span class="pun">(</span><span class="pln">np</span><span class="pun">.</span><span class="pln">unique</span><span class="pun">(</span><span class="pln">y</span><span class="pun">))])</span></code></li><li class="L3"><code></code></li><li class="L4"><code><span class="pln">    </span><span class="com"># plot the decision surface</span></code></li><li class="L5"><code><span class="pln">    x1_min</span><span class="pun">,</span><span class="pln"> x1_max </span><span class="pun">=</span><span class="pln"> X</span><span class="pun">[:,</span><span class="pln"> </span><span class="lit">0</span><span class="pun">].</span><span class="pln">min</span><span class="pun">()</span><span class="pln"> </span><span class="pun">-</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> X</span><span class="pun">[:,</span><span class="pln"> </span><span class="lit">0</span><span class="pun">].</span><span class="pln">max</span><span class="pun">()</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> </span><span class="lit">1</span></code></li><li class="L6"><code><span class="pln">    x2_min</span><span class="pun">,</span><span class="pln"> x2_max </span><span class="pun">=</span><span class="pln"> X</span><span class="pun">[:,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">].</span><span class="pln">min</span><span class="pun">()</span><span class="pln"> </span><span class="pun">-</span><span class="pln"> </span><span class="lit">1</span><span class="pun">,</span><span class="pln"> X</span><span class="pun">[:,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">].</span><span class="pln">max</span><span class="pun">()</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> </span><span class="lit">1</span></code></li><li class="L7"><code><span class="pln">    xx1</span><span class="pun">,</span><span class="pln"> xx2 </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">meshgrid</span><span class="pun">(</span><span class="pln">np</span><span class="pun">.</span><span class="pln">arange</span><span class="pun">(</span><span class="pln">x1_min</span><span class="pun">,</span><span class="pln"> x1_max</span><span class="pun">,</span><span class="pln"> resolution</span><span class="pun">),</span></code></li><li class="L8"><code><span class="pln">                           np</span><span class="pun">.</span><span class="pln">arange</span><span class="pun">(</span><span class="pln">x2_min</span><span class="pun">,</span><span class="pln"> x2_max</span><span class="pun">,</span><span class="pln"> resolution</span><span class="pun">))</span></code></li><li class="L9"><code><span class="pln">    Z </span><span class="pun">=</span><span class="pln"> classifier</span><span class="pun">.</span><span class="pln">predict</span><span class="pun">(</span><span class="pln">np</span><span class="pun">.</span><span class="pln">array</span><span class="pun">([</span><span class="pln">xx1</span><span class="pun">.</span><span class="pln">ravel</span><span class="pun">(),</span><span class="pln"> xx2</span><span class="pun">.</span><span class="pln">ravel</span><span class="pun">()]).</span><span class="pln">T</span><span class="pun">)</span></code></li><li class="L0"><code><span class="pln">    Z </span><span class="pun">=</span><span class="pln"> Z</span><span class="pun">.</span><span class="pln">reshape</span><span class="pun">(</span><span class="pln">xx1</span><span class="pun">.</span><span class="pln">shape</span><span class="pun">)</span></code></li><li class="L1"><code><span class="pln">    plt</span><span class="pun">.</span><span class="pln">contourf</span><span class="pun">(</span><span class="pln">xx1</span><span class="pun">,</span><span class="pln"> xx2</span><span class="pun">,</span><span class="pln"> Z</span><span class="pun">,</span><span class="pln"> alpha</span><span class="pun">=</span><span class="lit">0.4</span><span class="pun">,</span><span class="pln"> cmap</span><span class="pun">=</span><span class="pln">cmap</span><span class="pun">)</span></code></li><li class="L2"><code><span class="pln">    plt</span><span class="pun">.</span><span class="pln">xlim</span><span class="pun">(</span><span class="pln">xx1</span><span class="pun">.</span><span class="pln">min</span><span class="pun">(),</span><span class="pln"> xx1</span><span class="pun">.</span><span class="pln">max</span><span class="pun">())</span></code></li><li class="L3"><code><span class="pln">    plt</span><span class="pun">.</span><span class="pln">ylim</span><span class="pun">(</span><span class="pln">xx2</span><span class="pun">.</span><span class="pln">min</span><span class="pun">(),</span><span class="pln"> xx2</span><span class="pun">.</span><span class="pln">max</span><span class="pun">())</span></code></li><li class="L4"><code></code></li><li class="L5"><code><span class="pln">    </span><span class="kwd">for</span><span class="pln"> idx</span><span class="pun">,</span><span class="pln"> cl </span><span class="kwd">in</span><span class="pln"> enumerate</span><span class="pun">(</span><span class="pln">np</span><span class="pun">.</span><span class="pln">unique</span><span class="pun">(</span><span class="pln">y</span><span class="pun">)):</span></code></li><li class="L6"><code><span class="pln">        plt</span><span class="pun">.</span><span class="pln">scatter</span><span class="pun">(</span><span class="pln">x</span><span class="pun">=</span><span class="pln">X</span><span class="pun">[</span><span class="pln">y </span><span class="pun">==</span><span class="pln"> cl</span><span class="pun">,</span><span class="pln"> </span><span class="lit">0</span><span class="pun">],</span><span class="pln"> </span></code></li><li class="L7"><code><span class="pln">                    y</span><span class="pun">=</span><span class="pln">X</span><span class="pun">[</span><span class="pln">y </span><span class="pun">==</span><span class="pln"> cl</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">],</span></code></li><li class="L8"><code><span class="pln">                    alpha</span><span class="pun">=</span><span class="lit">0.6</span><span class="pun">,</span><span class="pln"> </span></code></li><li class="L9"><code><span class="pln">                    c</span><span class="pun">=</span><span class="pln">cmap</span><span class="pun">(</span><span class="pln">idx</span><span class="pun">),</span></code></li><li class="L0"><code><span class="pln">                    edgecolor</span><span class="pun">=</span><span class="str">'black'</span><span class="pun">,</span></code></li><li class="L1"><code><span class="pln">                    marker</span><span class="pun">=</span><span class="pln">markers</span><span class="pun">[</span><span class="pln">idx</span><span class="pun">],</span><span class="pln"> </span></code></li><li class="L2"><code><span class="pln">                    label</span><span class="pun">=</span><span class="pln">cl</span><span class="pun">)</span></code></li><li class="L3"><code></code></li><li class="L4"><code><span class="pln">    </span><span class="com"># highlight test samples</span></code></li><li class="L5"><code><span class="pln">    </span><span class="kwd">if</span><span class="pln"> test_idx</span><span class="pun">:</span></code></li><li class="L6"><code><span class="pln">        </span><span class="com"># plot all samples</span></code></li><li class="L7"><code><span class="pln">        </span><span class="kwd">if</span><span class="pln"> </span><span class="kwd">not</span><span class="pln"> versiontuple</span><span class="pun">(</span><span class="pln">np</span><span class="pun">.</span><span class="pln">__version__</span><span class="pun">)</span><span class="pln"> </span><span class="pun">&gt;=</span><span class="pln"> versiontuple</span><span class="pun">(</span><span class="str">'1.9.0'</span><span class="pun">):</span></code></li><li class="L8"><code><span class="pln">            X_test</span><span class="pun">,</span><span class="pln"> y_test </span><span class="pun">=</span><span class="pln"> X</span><span class="pun">[</span><span class="pln">list</span><span class="pun">(</span><span class="pln">test_idx</span><span class="pun">),</span><span class="pln"> </span><span class="pun">:],</span><span class="pln"> y</span><span class="pun">[</span><span class="pln">list</span><span class="pun">(</span><span class="pln">test_idx</span><span class="pun">)]</span></code></li><li class="L9"><code><span class="pln">            warnings</span><span class="pun">.</span><span class="pln">warn</span><span class="pun">(</span><span class="str">'Please update to NumPy 1.9.0 or newer'</span><span class="pun">)</span></code></li><li class="L0"><code><span class="pln">        </span><span class="kwd">else</span><span class="pun">:</span></code></li><li class="L1"><code><span class="pln">            X_test</span><span class="pun">,</span><span class="pln"> y_test </span><span class="pun">=</span><span class="pln"> X</span><span class="pun">[</span><span class="pln">test_idx</span><span class="pun">,</span><span class="pln"> </span><span class="pun">:],</span><span class="pln"> y</span><span class="pun">[</span><span class="pln">test_idx</span><span class="pun">]</span></code></li><li class="L2"><code></code></li><li class="L3"><code><span class="pln">        plt</span><span class="pun">.</span><span class="pln">scatter</span><span class="pun">(</span><span class="pln">X_test</span><span class="pun">[:,</span><span class="pln"> </span><span class="lit">0</span><span class="pun">],</span></code></li><li class="L4"><code><span class="pln">                    X_test</span><span class="pun">[:,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">],</span></code></li><li class="L5"><code><span class="pln">                    c</span><span class="pun">=</span><span class="str">''</span><span class="pun">,</span></code></li><li class="L6"><code><span class="pln">                    alpha</span><span class="pun">=</span><span class="lit">1.0</span><span class="pun">,</span></code></li><li class="L7"><code><span class="pln">                    edgecolor</span><span class="pun">=</span><span class="str">'black'</span><span class="pun">,</span></code></li><li class="L8"><code><span class="pln">                    linewidths</span><span class="pun">=</span><span class="lit">1</span><span class="pun">,</span></code></li><li class="L9"><code><span class="pln">                    marker</span><span class="pun">=</span><span class="str">'o'</span><span class="pun">,</span></code></li><li class="L0"><code><span class="pln">                    s</span><span class="pun">=</span><span class="lit">55</span><span class="pun">,</span><span class="pln"> label</span><span class="pun">=</span><span class="str">'test set'</span><span class="pun">)</span></code></li></ol></pre><ul data-anchor-id="7d5o">
<li>调用函数</li>
</ul><div class="md-section-divider"></div><pre class="prettyprint linenums prettyprinted" data-anchor-id="ym3n"><ol class="linenums"><li class="L0"><code><span class="pln">X_combined_std </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">vstack</span><span class="pun">((</span><span class="pln">X_train_std</span><span class="pun">,</span><span class="pln"> X_test_std</span><span class="pun">))</span></code></li><li class="L1"><code><span class="pln">y_combined </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">hstack</span><span class="pun">((</span><span class="pln">y_train</span><span class="pun">,</span><span class="pln"> y_test</span><span class="pun">))</span></code></li><li class="L2"><code></code></li><li class="L3"><code><span class="pln">plot_decision_regions</span><span class="pun">(</span><span class="pln">X</span><span class="pun">=</span><span class="pln">X_combined_std</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">=</span><span class="pln">y_combined</span><span class="pun">,</span></code></li><li class="L4"><code><span class="pln">                      classifier</span><span class="pun">=</span><span class="pln">ppn</span><span class="pun">,</span><span class="pln"> test_idx</span><span class="pun">=</span><span class="pln">range</span><span class="pun">(</span><span class="lit">105</span><span class="pun">,</span><span class="pln"> </span><span class="lit">150</span><span class="pun">))</span></code></li><li class="L5"><code><span class="pln">plt</span><span class="pun">.</span><span class="pln">xlabel</span><span class="pun">(</span><span class="str">'petal length [standardized]'</span><span class="pun">)</span></code></li><li class="L6"><code><span class="pln">plt</span><span class="pun">.</span><span class="pln">ylabel</span><span class="pun">(</span><span class="str">'petal width [standardized]'</span><span class="pun">)</span></code></li><li class="L7"><code><span class="pln">plt</span><span class="pun">.</span><span class="pln">legend</span><span class="pun">(</span><span class="pln">loc</span><span class="pun">=</span><span class="str">'upper left'</span><span class="pun">)</span></code></li><li class="L8"><code></code></li><li class="L9"><code><span class="pln">plt</span><span class="pun">.</span><span class="pln">tight_layout</span><span class="pun">()</span></code></li><li class="L0"><code><span class="com"># plt.savefig('./figures/iris_perceptron_scikit.png', dpi=300)</span></code></li><li class="L1"><code><span class="pln">plt</span><span class="pun">.</span><span class="pln">show</span><span class="pun">()</span></code></li></ol></pre></div>
</body>
</html>